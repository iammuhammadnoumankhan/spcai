---
title: Patents
---

# Patents

## Label-based Data Representation I/O Process and System

_Patent No. 11,630,834_

Abstract: A system and method for executing input/output (I/O) tasks for clients in a distributed
computing system. One or more I/O requests made by a client are received. The operation instructions
for the request data in the I/O requests are separated from the request data. A data representation
called data label (or label) is created for executing operation instructions of the I/O requests.
A data label corresponds to each of the I/O request and includes a unique identifier, information
to the source and/or destination for the request data, and an operation instruction separated from
the request data. The data label is pushed into a distributed label queue and is dispatched to an
individual worker node according to a scheduling policy. The worker node executes the I/O tasks by
executing the dispatched data label. The system and method can execute I/O tasks independently and
decoupled from the client applications.

## Methods and Devices for Layered Performance Matching in Hierarchical Memory

_Patent No. 9,846,646_

Abstract: A method of optimizing memory access in a hierarchical memory system. The method includes
determining a request rate from an i'th layer of the hierarchical memory system for each of n layers
in the hierarchical memory system. The method also includes determining a supply rate from an (i+1)'th
layer of the hierarchical memory system for each of the n layers in the hierarchical memory system.
The supply rate from the (i+1)'th layer of the hierarchical memory system corresponds to the request
rate from the i'th layer of the hierarchical memory system. The method further includes adjusting a
set of computer architecture parameters of the hierarchical memory system or a schedule associated
with an instruction set to utilize heterogeneous computing resources within the hierarchical memory
system to match a performance of each adjacent layer of the hierarchical memory system.

## Timing-Aware Data Prefetching for Microprocessors

_Patent No. 8,856,452_

Abstract: A method and apparatus for prefetching data from memory for a multicore data processor. A prefetcher
issues a plurality of requests to prefetch data from a memory device to a memory cache. Consecutive cache
misses are recorded in response to at least two of the plurality of requests. A time between the cache misses
is determined and a timing of a further request to prefetch data from the memory device to the memory cache
is altered as a function of the determined time between the two cache misses.

## Systems, Methods, and Protocols for Process Migration and Group Membership Management

_Patent No. 8,335,813_

Abstract: A system, method, and set of protocols for dynamic group communication are provided for enabling dynamic
process migration and dynamic group membership management. A process in a group receives and distributes a migration
signal. Group communication continues while the processes in the group asynchronously reach a global superstep and
then a synchronization point. The processes then spawn a new process on a new device and update group membership
information. The new process operates in continuous execution with the new group.

## Memory Server

_Patent No. 7,865,570_

Abstract: A memory server provides data access as a service to clients and has a memory service architecture and
components for removing data management burdens from the client processor and providing increased speed and utility
for the client through aggressive prediction of client memory requirements and fast provision of data.

## Communication and Process Migration Protocols for Distributed Heterogeneous Computing

_Patent No. 7,065,549_

Abstract: Communication and Process Migration Protocols instituted in an independent layer of a virtual machine environment
allow for heterogeneous or homogeneous process migration. The protocols manage message traffic for processes communicating
in the virtual machine environment. The protocols manage message traffic for migrating processes so that no message traffic
is lost during migration, and proper message order is maintained for the migrating process. In addition to correctness of
migration operations, low overhead and high efficiency is achieved for supporting scalable, point-to-point communications.
